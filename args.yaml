##################
### FILE PATHS ###
##################
# experiment directory
model_dir: exp_deeplab_v4

data_path: multi-task-fcn/16.0_version_data

# Input data for the model
ortho_image: input_data/orthoimage/fixed_ortoA1_25tiff.tif
train_segmentation_path: "input_data/segmentation/samples_A1_train2tif.tif"
test_segmentation_path: "input_data/segmentation/samples_A1_test2tif.tif"

mask_path: "input_data/mask.tif"


checkpoint_file: checkpoint.pth.tar

# Num of iter
num_iter : 5

# pred2raster parameters
# samples per epoch
overlap: [0.1, 0.4, 0.6]
# 1: Random selection, 2: 4 region, 3: chessboard
train_protocol: 1
# True for training with 1 fold and testing with 3. False otherwise
small_train_set: False
# True for predicting only the test ITCs
test_itc: False


# num samples per epoch
samples: 2500
# True for data augmentation during training
augment: True

# convnet architecture --> 'resunet','deeplabv3_resnet50'
arch: deeplabv3_resnet50
# True for load pretrained weights from Imagenet
is_pretrained: True

# True for frozen the resnet backbone
frozen: False
# Filter for the ResUnet for trained from scratch
filters: [32, 32, 32, 32]

### optim parameters ###
# number of total epochs to run
epochs: 30
# batch size per gpu, i.e. how many unique instances per gpu
batch_size: 8
# base learning rate
base_lr: 0.01
# final learning rate
final_lr: 0.0001
# number of warmup epochs
warmup_epochs: 5
# initial warmup learning rate
start_warmup: 0.0

# weight decay
weight_decay: 1e-06

### dist parameters ###
# url used to set up distributed training; see https://pytorch.org/docs/stable/distributed.html
dist_url: env://
# number of processes: it is set automatically and should not be passed as argument
world_size: -1
# rank of this process: it is set automatically and should not be passed as argument
rank: 0
# this argument is not used and should be ignored
local_rank: 0

### others parameters ###
# number of data loading workers
workers: 0
# seeds
seed: [31, 10, 75, 102, 40]


###############################
#### Evaluation parameters ####
###############################

# True for training 4 disjoint regions
size_crops: 256
# NÃºmero de classes
nb_class: 14

# True for patch wise classification
patch_wise: False
# True for load model from path
load_model_from_path: True

# Save the model periodically
checkpoint_freq: 1
# whether to train with mixed precision or not
use_fp16: True
# synchronize bn
sync_bn: pytorch
# see
syncbn_process_group_size: 8